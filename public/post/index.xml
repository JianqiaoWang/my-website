<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Jianqiao Wang</title>
    <link>https://academic-demo.netlify.app/post/</link>
      <atom:link href="https://academic-demo.netlify.app/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Tue, 25 Feb 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://academic-demo.netlify.app/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>Posts</title>
      <link>https://academic-demo.netlify.app/post/</link>
    </image>
    
    <item>
      <title>A hitchhiker&#39;s guide to research (凡人科研指南)</title>
      <link>https://academic-demo.netlify.app/post/guide-to-research/</link>
      <pubDate>Tue, 25 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/guide-to-research/</guid>
      <description>


&lt;p&gt;学生时期对于学习生活有些思考，趁还记得住（或者说保持着年轻人的思维方式），特别分享出来，希望能对未来学生有所助益。本文随机更新！&lt;/p&gt;
&lt;div id=&#34;提问和被提问&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;1. 提问和被提问&lt;/h3&gt;
&lt;p&gt;提问与被提问是高等教育最重要的部分之一，也是个人成长和科研进步的关键环节。&lt;/p&gt;
&lt;div id=&#34;面对评论和问题&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;面对评论和问题&lt;/h4&gt;
&lt;p&gt;保持开放和感激的心态。从个人经验来看，每个人的时间和思考力都很宝贵，别人愿意对你的工作提出问题，是因为他们真的感兴趣，认为工作有启发性或者还有很大的提升空间。相反，对于不感兴趣的工作，我们往往只是客套地说一句“很好”或“做得不错”。因此，面对一些尖锐的问题，要实事求是，不要应激反应，不要过度防御，更无需内耗，结合别人的意见，努力提高自己；这种心态可以解决大部分的自我困扰。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;学会提出有助益的问题和评论&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;学会提出有助益的问题和评论&lt;/h4&gt;
&lt;p&gt;能够提出准确且深刻的问题是一项高级技能，需要长期不断的训练。因此，从学生时期开始有意识地提高这一能力是非常必要的。但遗憾的是，这种提问能力（或者说批判性思维）我目前也还想到好的方法进行训练，唯一的建议就是多交流、多思考、多阅读、多参加会议。正所谓：“操千曲而后晓声，观千剑而后识器。”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;博士训练专业性和一万小时定律&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;2. 博士训练、专业性和一万小时定律&lt;/h3&gt;
&lt;p&gt;五年的博士训练，严格来说，是一万小时定律的体现，即每年工作 2000 小时 = 8 小时/天 × 250 天，让被训练者从普通人蜕变为小小专家。因此，博士训练更是一种职业性训练，就像奥运选手的训练，最终是为了更好的迎接职业挑战，因此要对其艰苦性有所准备。很多同学常常选择进一步深造，只是为了延迟成为社会人，这种看法是有问题的。客观来说，读博本身就是一个工作，但好处在于更自由更灵活，你会有更平等和广泛的机会去学习和提高。&lt;/p&gt;
&lt;p&gt;另一方面，你身边的同学不是你的内卷对手，而是提高你能力的伙伴，是你的探索之时边界的同行者。因此，请珍惜身边的伙伴，努力从他们的思考中获得启发，不断加强交流，提高自己的能力。&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;关于学术报告和交流&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;3. 关于学术报告和交流&lt;/h3&gt;
&lt;p&gt;科研最终还是需要交流，院系举办学术报告，邀请资深学者进行学术交流是不可或缺的一部分。通常，我们会预留一些时间，让学生与教授交流。然而，许多年轻学子因为性格害羞或者不知道该问什么，而错失了这个机会。实际上，这种交流对于认识学术圈、选择未来职业方向，以及培养科研品味都极为重要。为访问学者带去一些好奇心的洗礼，帮助他们保持年轻开放的心态，也是变相让他们满载而归，而不是空手离开。&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Working with the reference genotype data</title>
      <link>https://academic-demo.netlify.app/post/working-with-the-reference-genotype-data/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/working-with-the-reference-genotype-data/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The reference genotype database has been widely used for GWA studieds. It provides more information on the genetic variants when the individual-level genotype data is not available or the genotypes data has low sequencing depth. The reference also has been used for imputing the missing genotypes to boost the power of GWAS.&lt;/p&gt;
&lt;p&gt;Common reference panels include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HapMap3 reference panels: Early reference panels&lt;/li&gt;
&lt;li&gt;1000 Genomes Phase3  (1KGP, widely used), 2506 individuals from 26 populations, 49,143,605 Sites. 504 individuals for European ancestry.&lt;/li&gt;
&lt;li&gt;The Haplotype Reference Consortium (HRC), the first release consists of 64,976 haplotypes at 39,235,157 SNPs. Mainly european ancestry but also includes 1KGP&lt;/li&gt;
&lt;li&gt;Topmed reference panel. Version r2 of the panel includes 97,256 reference samples and 308,107,085 genetic variants distributed across the 22 autosomes and the X chromosome.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not all reference panels are public. Large reference needs some applications . Here we focus on working with 1KGP reference panel.&lt;/p&gt;
&lt;h1 id=&#34;work-with-1kgp&#34;&gt;Work with 1KGP&lt;/h1&gt;
&lt;h2 id=&#34;access-to-the-1kgp-project-data&#34;&gt;access to the 1KGP project data&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Raw genotype varaint call files (vcf) could be downloaded from &lt;a href=&#34;http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/&lt;/a&gt; at each chromosome. However, we remind the loci of variants were determined for version GRCh37.
&lt;ul&gt;
&lt;li&gt;Variants on GRCh38 should check the information about the data collection at : &lt;a href=&#34;https://www.internationalgenome.org/data-portal/data-collection/30x-grch38&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.internationalgenome.org/data-portal/data-collection/30x-grch38&lt;/a&gt;. It contains 2504 unrelated individuals and additional 698 related samples with high coverage.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To convert them to the plink file, we need to run following commands:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-shell&#34;&gt;for j in {1..22}; do
wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/release/20130502/ALL.chr$j.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
./plink --make-bed --out chr$j --maf 0.01 --vcf ALL.chr$j.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz
done
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;The plink file format of 1KGP could be found in &lt;a href=&#34;https://www.coggenomics.org/plink/2.0/resources#1kg_phase3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.coggenomics.org/plink/2.0/resources#1kg_phase3&lt;/a&gt; in all_phase3.pgen, .psam, .pvar format&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;plink2 --pfile all_phase3 --pgen-info # check the information 
# or use the following command if all_phase3 is zst compressed
plink2 --pfile all_phase3 vzs --pgen-info # check the information 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The output is the information of the genotypes&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;--pgen-info on all_phase3.pgen:
  Variants: 84805772
  Samples: 2504
  REF alleles are all known
  Maximum allele count for a single variant: &amp;gt;2, not explicitly stored
  Explicitly phased hardcalls present
  No dosages present
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we extract the European indviduals with maf &amp;gt; 0.01 amd remove snps with multi allels, duplicate posisions and names&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;
plink2 --pfile all_phase3 &#39;vzs&#39; --keep-if SuperPop == EUR --rm-dup exclude-all --snps-only  &#39;just-acgt&#39; --max-alleles 2 --chr 1-22 --maf 0.01 --make-bed --out all_phase3_eur_maf_0.01

&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-result&#34;&gt;2504 samples (1271 females, 1233 males; 2497 founders) loaded from
all_phase3.psam.
77818345 out of 84805772 variants loaded from all_phase3.pvar.zst.
2 categorical phenotypes loaded.
--rm-dup: 191 duplicated IDs, 382 variants removed.
--keep-if: 2001 samples removed.
503 samples (263 females, 240 males; 503 founders) remaining after main
filters.
Calculating allele frequencies... done.
69267844 variants removed due to allele frequency threshold(s)
(--maf/--max-maf/--mac/--max-mac).
8550119 variants remaining after main filters.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Download and insert genetic distances&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;
plink --bfile all_phase3_eur_maf_0.01 --cm-map ./genetic_map/genetic_map_chr@_combined_b37.txt --make-bed --out all_phase3_eur_maf_0.01_ctm

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Replace predictor names with generic names of the form Chr:BP (often not required, but I find this format more convenient). It is useful to create a file containing the original names, generic names and alleles.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-batch&#34;&gt;genofile=&#39;all_phase3_eur_maf_0.01&#39;
awk &amp;lt; ${genofile}_ctm.bim &#39;{$2=$1&amp;quot;:&amp;quot;$4;print $0}&#39; &amp;gt; ${genofile}_ref.bim
awk &amp;lt; ${genofile}_ctm.bim &#39;{print $2, $1&amp;quot;:&amp;quot;$4, $5, $6}&#39; &amp;gt; ${genofile}_ref.names
cp ${genofile}_ctm.bed ${genofile}_ref.bed
cp ${genofile}_ctm.fam ${genofile}_ref.fam
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we remove the intermediate results and keep the ${genofile}_ref files as our reference panel.&lt;/p&gt;
&lt;p&gt;Reference&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://dougspeed.com/reference-panel/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://dougspeed.com/reference-panel/&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.cog-genomics.org/plink/2.0/filter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cog-genomics.org/plink/2.0/filter&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;A helpful tool for analyzing the GWAS data: plinkQC (Discussed later)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Working with the summary association statistics</title>
      <link>https://academic-demo.netlify.app/post/working-with-the-summary-association-statistics/</link>
      <pubDate>Sat, 27 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/working-with-the-summary-association-statistics/</guid>
      <description>&lt;p&gt;Working with the summary association statistics has been important in current GWAS studies. However, generated from different cohorts, the format of summary association statistics varies a lot. In this post, we discuss how to do the preprocessing for summary association statistics.&lt;/p&gt;
&lt;p&gt;Useful links&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://dougspeed.com/summary-statistics/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://dougspeed.com/summary-statistics/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Step 0: Preparation for the genomic simulation</title>
      <link>https://academic-demo.netlify.app/post/step-0-preparation-for-the-genomic-simulation/</link>
      <pubDate>Thu, 25 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/step-0-preparation-for-the-genomic-simulation/</guid>
      <description>&lt;p&gt;To do simulation with genetic data, we need to make some preparion. First, we detemine the snplist and individuals in the genotype data:&lt;/p&gt;
&lt;p&gt;snplist.txt&lt;/p&gt;
&lt;p&gt;Prepare data for package bigsnpr and bigstatsr&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;library(bigsnpr)
library(bigstatsr)
PrepareX = FALSE

#-------------------------------------------------------
if(PrepareX){
rds = bigsnpr::snp_readBed2(bedfile = &amp;quot;../../Cric_HF_RealData/rawdata/cric.filtered.maf0.01.bed&amp;quot;,
                     backingfile = &amp;quot;cric_geno&amp;quot;,ind.col= ind.column)
geno &amp;lt;- snp_attach(rds)
G &amp;lt;- geno$genotypes
CHR &amp;lt;- geno$map$chromosome
infos &amp;lt;- snp_fastImputeSimple(G, method = &amp;quot;mean2&amp;quot;)
# To make this permanent, you need to save (modify) the file on disk
geno$genotypes &amp;lt;- infos
geno &amp;lt;- snp_save(geno)
G &amp;lt;- geno$genotypes
ind.keep &amp;lt;- snp_clumping(G, infos.chr = geno$map$chromosome,
                        infos.pos = geno$map$physical.pos,
                        thr.r2 = 0.01)
saveRDS(ind.keep, file =&amp;quot;ind_keep_clump.rds&amp;quot;)
data.table::fwrite( as.data.frame(geno$map$marker.ID), file = &amp;quot;snplist.txt&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prepare for the GCTA method&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;ref.bed = &amp;quot;../../Cric_HF_RealData/rawdata/cric.filtered.maf0.01&amp;quot;
MakeGRM = function(ref.bed, keep.snp, keep.ind, output.dir = &amp;quot;./temp/&amp;quot;){

  grm = paste0(output.dir, &amp;quot;geno&amp;quot;)

  fwrite(data.frame(keep.snp), file = paste0(output.dir,&amp;quot;snplist.txt&amp;quot;), quote = F, sep = &amp;quot;\t&amp;quot;, col.names=T, na = &amp;quot;NA&amp;quot;)

  system(paste0(&amp;quot;plink --bfile &amp;quot;, ref.bed, &amp;quot; --extract &amp;quot;, paste0(output.dir, &amp;quot;snplist.txt&amp;quot;), &amp;quot; --make-grm-bin --out &amp;quot;, grm ) )
}
# alternative, slower
#system(paste0(&amp;quot;./gcta64 --bfile &amp;quot;, ref.bed, &amp;quot; --extract &amp;quot;, paste0(output.dir, &amp;quot;snplist.txt&amp;quot;), &amp;quot; --make-grm-bin --out &amp;quot;, grm #) )
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Prepare for the LD Score regression : Calculate the ld score&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;System(&amp;quot;ldsc.py --bfile ../../Cric_HF_RealData/rawdata/cric.filtered.maf0.01 --extract ./temp/snplist.txt --ld-wind-kb 1000 --out ./temp/geno&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Simulation and analysis with R and LDSC</title>
      <link>https://academic-demo.netlify.app/post/simulation-and-analysis-with-r-and-ldsc/</link>
      <pubDate>Tue, 23 Nov 2021 00:00:00 +0000</pubDate>
      <guid>https://academic-demo.netlify.app/post/simulation-and-analysis-with-r-and-ldsc/</guid>
      <description>&lt;p&gt;My dissertation research always needs to do comparison with the GCTA-GREML and LDSC.Here is an introduction of R analysis with LDSC and GCTA&lt;/p&gt;
&lt;h3 id=&#34;gcta&#34;&gt;GCTA&lt;/h3&gt;
&lt;p&gt;GCTA is a wonderful software designed for the dealing with the GWAS data. On the other hand, it does not always fit in the common  statistical simulation pipeline, particualy for the software R. This post is used to document how to do statistical simulation with R and GCTA based on a give genotype file.&lt;/p&gt;
&lt;p&gt;What we need:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;phenotype file Y1, Y2&lt;/li&gt;
&lt;li&gt;Genotype file  geno.bed&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;First, we generate the GRM file based on the genotype file. This function only need be estimated once&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;MakeGRM = function(ref.bed, keep.snp, keep.ind, output.dir = &amp;quot;./temp/&amp;quot;){

  grm = paste0(output.dir, &amp;quot;geno&amp;quot;)

  fwrite(data.frame(keep.snp), file = paste0(output.dir,&amp;quot;snplist.txt&amp;quot;), quote = F, sep = &amp;quot;\t&amp;quot;, col.names=T, na = &amp;quot;NA&amp;quot;)

  system(paste0(&amp;quot;plink --bfile &amp;quot;, ref.bed, &amp;quot; --extract &amp;quot;, paste0(output.dir, &amp;quot;snplist.txt&amp;quot;), &amp;quot; --make-grm-bin --out &amp;quot;, grm ) )
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the second step, we need to write out the phenotype file based on the FID and IID&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;WritePheno = function( Y1, Y2, FID, IID, pheno.file  ){

  pheno = data.frame(FID = FID, IID = IID,
                     Y1 = Y1, Y2 = Y2)
  
  fwrite(pheno, file = pheno.file,
         quote = F, sep = &amp;quot;\t&amp;quot;, col.names=T, na = &amp;quot;NA&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we implement the GCTA,&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SimuGCTA = function(geno.file, pheno.file, output.dir){

  output.file = paste0(output.dir, &amp;quot;GCTA.result&amp;quot;)

  system(paste0(&amp;quot;./gcta64 --reml-bivar --grm &amp;quot;,
                geno.file,&amp;quot; --pheno &amp;quot;, pheno.file,
                &amp;quot; --thread-num 20 --out &amp;quot;, output.file ))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When the simulated errors have no covariance, we could specify &amp;ndash;reml-bivar-nocove for fair comparison. To test for the non-zero genetic covariance, ** &amp;ndash;reml-bivar-lrt-rg 0 ** could be used.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SimuGCTA.test = function(geno.file, pheno.file, output.dir){

  output.file = paste0(output.dir, &amp;quot;GCTA.result&amp;quot;)
  
  system(paste0(&amp;quot;./gcta64 --reml-bivar-nocove --reml-maxit 100 --grm &amp;quot;, 
                geno.file,&amp;quot; --pheno &amp;quot;,
                pheno.file,&amp;quot; --reml-bivar-lrt-rg 0 --out &amp;quot;,output.file))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Read GCTA output file&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;read.GCTA = function(output.dir, LRT = T){
  
   filename = paste0(output.dir, &amp;quot;GCTA.result.hsq&amp;quot;)
    if(file.exists(filename)){
      hsq = data.table::fread(filename, fill = T)
      Est = as.vector(t( hsq[1:3, 2:3])) %&amp;gt;% 
    setNames(c(&amp;quot;Heri.1&amp;quot;,&amp;quot;Heri.1.Se&amp;quot;,&amp;quot;Heri.2&amp;quot;,&amp;quot;Heri.2.Se&amp;quot;, &amp;quot;GeCv&amp;quot;,&amp;quot;GeCv.Se&amp;quot; ))
      if(LRT){
      pval = as.numeric(sapply(strsplit(as.character(hsq[hsq$Source == &amp;quot;Pval&amp;quot;,2]), &amp;quot;\\(&amp;quot;), &amp;quot;[[&amp;quot;, 1))
      }
    }
   return(list(Est = Est, pval = pval))
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ldsc&#34;&gt;LDSC&lt;/h3&gt;
&lt;p&gt;First, we generate the ld score based on the genotype file. This function only need be estimated once&lt;/p&gt;
&lt;p&gt;module load ldsc
source activate ldsc-1.0.1
ldsc.py &amp;ndash;bfile geno  &amp;ndash;ld-wind-cm 1 &amp;ndash;out chr1_select
ldsc.py &amp;ndash;bfile ../../Cric_HF_RealData/rawdata/cric.filtered.maf0.01 &amp;ndash;extract ./temp/snplist.txt &amp;ndash;ld-wind-kb 1000 &amp;ndash;out ./temp/geno&lt;/p&gt;
&lt;p&gt;Implement the LDSC regression&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;SimuLDSC = function(Z1, N1, Z2, N2, Nc=0, weight=T, CSTR = T,
                           info = NA, LDSCORE, corenum = 1, output.dir){
  
  if(length(Z1) != length(Z2) ){stop(&amp;quot;Z scores should have the same length.&amp;quot;)}

  if(!is.na(info)){
    print(&amp;quot;update info&amp;quot;)
    Z1.data = data.frame(SNP = info$SNP , Z = Z1, N =  N1,
                         A1 =  &amp;quot;A&amp;quot;, A2 = &amp;quot;G&amp;quot;, stringsAsFactors = F)
    colnames(Z1.data) = c(&amp;quot;SNP&amp;quot;,  &amp;quot;Z&amp;quot;, &amp;quot;N&amp;quot;, &amp;quot;A1&amp;quot;, &amp;quot;A2&amp;quot;)
    fwrite(Z1.data, file = paste0(output.dir, &amp;quot;Z1.sumstats&amp;quot;) , quote = F, sep = &amp;quot;\t&amp;quot;, col.names=T, na = &amp;quot;NA&amp;quot; )
    Z2.data = data.frame(SNP = info$SNP , Z = Z2, N =  N2,
                         A1 = &amp;quot;A&amp;quot;,  A2 = &amp;quot;G&amp;quot;, stringsAsFactors = F)
    colnames(Z2.data) = c(&amp;quot;SNP&amp;quot;, &amp;quot;Z&amp;quot;, &amp;quot;N&amp;quot;, &amp;quot;A1&amp;quot;, &amp;quot;A2&amp;quot;)
    fwrite(Z2.data, file = paste0(output.dir, &amp;quot;Z2.sumstats&amp;quot;), quote = F, sep = &amp;quot;\t&amp;quot;, col.names=T, na = &amp;quot;NA&amp;quot; )
  }
  if(weight == T){
    name = paste0(output.dir, &amp;quot;LDSC&amp;quot;)
    system(paste0(&amp;quot;ldsc.py --rg &amp;quot;,paste0(J, &amp;quot;Z1.sumstats,&amp;quot;), paste0(J, &amp;quot;Z2.sumstats&amp;quot;),
                  &amp;quot; --ref-ld &amp;quot;, LDSCORE,&amp;quot; --w-ld &amp;quot;,LDSCORE,&amp;quot; --intercept-h2 1,1 --out &amp;quot;,name))
  }else{

    stop()

  } 
  }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;read the LDSC output&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;read.LDSC = function(output.dir){
  H = fread(paste0(output.dir, &amp;quot;LDSC.log&amp;quot;), fill = T)
  result.all = rep(NA, 8)
  result.gecr = unlist(H[(stringr::str_detect(unlist(H), &amp;quot;Genetic Correlation:&amp;quot;))]) %&amp;gt;% str_split(, pattern = &amp;quot; &amp;quot;) %&amp;gt;% unlist()
  result.heri = unlist(H[(stringr::str_detect(unlist(H), &amp;quot;Total Observed scale h2:&amp;quot;))]) %&amp;gt;%  str_split(, pattern = &amp;quot; &amp;quot;) %&amp;gt;% unlist()
  result.gecov = unlist(H[(stringr::str_detect(unlist(H), &amp;quot;Total Observed scale gencov:&amp;quot;))]) %&amp;gt;% str_split(, pattern = &amp;quot; &amp;quot;) %&amp;gt;% unlist()
  result.P = unlist(H[(stringr::str_detect(unlist(H), &amp;quot;P:&amp;quot;))]) %&amp;gt;%
    str_split(, pattern = &amp;quot; &amp;quot;) %&amp;gt;% unlist()

  if(!is.null(result.gecr)){
    result =  as.numeric(unlist(regmatches(result.gecr,gregexpr(&amp;quot;-?\\ *[0-9]+\\.?[0-9]*(?:[Ee]\\ *-?\\ *[0-9]+)?&amp;quot;,result.gecr, perl=TRUE))))
    result.all[1] = result[1]
    result.all[2] = result[2]
  }

  if(!is.null(result.heri)){
    result =  as.numeric(unlist(regmatches(result.heri,
                                           gregexpr(&amp;quot;-?\\ *[0-9]+\\.?[0-9]*(?:[Ee]\\ *-?\\ *[0-9]+)?&amp;quot;,
                                                    result.heri, perl=TRUE))))
    result.all[3] = result[2]
    result.all[4] = result[3]
    result.all[5] = result[5]
    result.all[6] = result[6]
  }

  if(!is.null(result.gecov)){

    result =  as.numeric(unlist(regmatches(result.gecov,
                                           gregexpr(&amp;quot;-?\\ *[0-9]+\\.?[0-9]*(?:[Ee]\\ *-?\\ *[0-9]+)?&amp;quot;,
                                                    result.gecov, perl=TRUE))))
    result.all[7] = result[1]
    result.all[8] = result[2]
    zscore = result[1]/result[2]
    pvalue = 2* (1 - pnorm(abs(zscore)))
  }else{
    pvalue = NA
  }
  return( c(GeCv.pv = pvalue, GeCr.pv = as.numeric(result.P[2])) )
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
